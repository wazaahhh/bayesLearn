\section{Introduction}
From financial stability to the stability of democracies, beliefs play a central role in our explanation of many phenomena. In the social sciences, these beliefs are often conceptualized as probabilistic assessments over states of the world.  However, they are derived from coherent belief systems people hold in their minds regarding how the world works as supported by recent work in cognitive science \cite{lombrozo2006structure, anderson1990cognitive}.  How do humans learn in simple and in complex systems?  How efficiently do they explore the space of possible beliefs and how closely is the direction of exploration tied to experience?  Bayesian approaches of learning would not be feasible for realistically complex systems, given recall constraints and they are not defined in cases where initial beliefs are such that they put zero weight on possible outcomes.  

Our work presents new experimental results on the rate at which people learn in more or less complex environments. We find that learning rates are much slower than they would be if learners were Bayesians, as had been proposed in older economic theories \cite{Boyer84, Prescott72, Rothschild74, McLennan84, Mirman84, Easley89, Kiefer89}. We also find that the learning rate is slightly higher when people build models of systems that are less complex and that even if the rates were identical, accuracy is always higher when the system is structurally simpler because initial models are closer aligned with reality.  


When searching for solutions to outstanding problems, here the formation of coherant belief structures that explain experience, humans must come up with innovative solutions.  We show that their strategies can be productively modeled as random search processes, combined with the consolidation of past and current experience. 

We show how people go through the resolution of a complicated problem, starting from no knowledge through L'evy random search, involving synthesizing current knowledge versus exploring out-of-the b\
ox (see Figure \ref{fig:schematic}). We then measure how this process leads to convergence, albeit very slow convergence, to the solution.

We then tie this result to well known theories and empirical results related to random search processes which are ubiquitous across the life sciences and in computer science (the sciences of the artificial).  
  The problem seems to be linked to the well documented fact that humans are unable to generate truly random signals; they are pattern creators and pattern synthesizers.  Once they have explored regions of the space that they seek to learn something about, they tend to return to past patterns and construct mental combinations of different patterns that they have already explored in the past and it seems to be harder and harder as time goes on for humans to explore new regions in the space that they have not already visited before.

For some time now, cognitive scientists have posed that modeling people's beliefs about causation in the material world provides an effective explanatory framework for how we process information and learn from these observations \cite{Griffiths2008}.  Probabilistic causes and effects, in other words, make up an important construct we seem to make use of when we seek to understand our world.  Bayes Nets are well-defined mathematical objects corresponding to an intuitive representation of causal beliefs.  They are easy to manipulate, do inference with and use as a means to compare different beliefs.  The kinds of Bayes Nets that have been allowed for in experimental settings up to this point, however, have been extremely simplistic and there has been an unanswered call for learning experiments with increased complexity (Griffiths?).  Our work is to our knowledge the first answer to this call.  

The data used in this work come from an experiment that we ran using an innovative experimental platform designed to measure how participants form and update causal beliefs in more or less complex settings.  In the experiment, participants see a data stream: data about multiple binary variables in a system, which take on the value High or Low. For example, one variable could be a stock price and there may be a number of variables that explain its variation or are explained by its variation in turn.  A visual interface allows the subjects to draw a causal model of the system. The platform then computes predictions on the basis of the participant's causal model and makes those prediction visible to the participant. The participant then makes bets using these predictions. In doing so, the participant gets feedback on the accuracy of her beliefs, and can update her beliefs by modifying the causal model. The platform thus allows us to observe beliefs and learning in a very precise and controlled way.

As can be seen in Figure \ref{fig:decay}, the distance between a person's evolving belief system about some physical system and the long-run absorbing distribution, which we interpret as a performance score, decays with time in a very specific way:

\begin{equation}
\label{ }
d(belief_{i, t}, absorbing distribution) = \alpha*t^{-\beta_i}
\end{equation}



The functional form of human learning in the context of our experiment, then, is the same as for the Bayesian learner, but the decay rate, $\beta$, of a human learner is much smaller than that of a Bayesian. 


