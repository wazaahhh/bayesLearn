\section{Literature Review}
The cognitive science and economics literatures have found much evidence in support of consistency with as well as deviance from human learning with Bayesian constructs of learning. On average, especially when incentives are high and tasks extremely simple, subjects update their beliefs based on new data in a way that is consistent with Bayes rule. However, at the individual level, there are large variations, as well as systematic departures under certain conditions.  In these literatures, comparing human learning to Bayesian updating, observed deviations can be organized in terms of "biases" or "heuristics".  Deterministic bias may have the consequence of underweighting or overweighting evidence ('law of small numbers' ) relative to base rates.  Such biases are in turn explained by the concept of availability heuristic (Griffin and Tversky 1992), which reduces data to examples that immediately come to mind, rather than by considering the exhaustive data of all previous experience and it has the consequence of slowing learning.  An example of the latter is recency bias \citep{FudenbergPeysakhovich2014}.  Another obstacle to efficient learning is when ambiguous information is taken to be a confirmation of a currently held hypothesis, or when information is suboptimally acquired or remembered.  Additionally, people have been found having difficulties with contingent reasoning with regards to future events \citep{CharnessLevin2009}. 
 
A different literature, associated with many disparate disciplines, such as ecology, cognitive science and complex systems frames learning and behavior in uncertain environments in terms of search, a ubiquitous property of life (Hills, Thomas T. et al. 2015).  Search, in turn, is a process of exploration and exploitation.  If behavior remains stable over some period of time, is focused and stays within a narrow subspace of the feasible decision or belief space it is interpreted as exploitation.  If it is erratic and moves wildly, it is interpreted as exploration (Mehlhorn et al, 2015).   

%These departures are clues to the heuristics humans use in their judgments, which overall often approximate bayesian inference but are not equivalent. Although many of these deviations imply that learning should be slower than predicted by Bayes rule,  few experiments measure the rate of learning and how far it departs from Bayesian inference.  

But why should one search and not simply count past events as Bayesian and Frequentist rationality demand (co-occurrences of values of a set of variables)?  With regards to counting observed frequencies of co-occurrences in order to measure covariances between a set of variables, if the number of variables gets large, the number of possible co-occurrences becomes astronomical.  Thus, remembering how many times a particular constellation of values of a given set of variables co-occurred puts ever increasing demands on memory as the set of variables gets large.  "In any system responsible for managing a vast data base there must be failures of retrieval" (Anderson, J. R., & Schooler, L. J. 1991).  Hence optimality must not mean Bayesian or Frequentist optimality, as counting all possible co-occurrences is not feasible because of limits on memory.  Additionally, there is the problem of assigning beliefs to never before experienced co-occurrences.  Note that Anderson, J. R., & Schooler, L. J. 1991 present not an argument about specific human biases or heuristics but rather one that presupposes a different definition of optimality that takes natural limits into consideration.  Our work begins with this same definitional premiss.  In addition to their own findings, Anderson, J. R., & Schooler, L. J. 1991 review the pervasive findings of power functions in the learning literature with respect to positive and negative performance measures and time.  As long as the performance measure is either unbounded or does not approach its bounds, the relationship between performance and time seems to follow the functional form:
$$P = A*T^{b},$$
where $b$ is negative and $P$ can either have negative valence, such as number of trials necessary to learn someone's name, or positive valence such as probability of having retained a name. In our case, the measure is bounded, above by 1 and below by 0, but never approaches either of its bounds. 

Learning of statistical systems can also be seen as search processes in simplex-spaces. If we consider learning as searching with feedback and we may do so if we find that brains learn as brains search, then another literature becoomes relevant that has not been generally considered by those studying learning; the literature concerened with foraging and the sort of spacial learning that had been most relevant throughout human evolution.  For most of our evolutionary history there were no stock and insurance markets and thus there is no reason to believe that our brains were optimized for the sort of learning that is optimal in those modern scenarios.      
%We find that it is not (slower). Furthermore, we also find that the quality of the inferences at each time space and across players varies a lot, following a "punctuated equilibrium" pattern. These observations are thus additional clues about the cognitive processes at play, with fine-grained information about how subjects update their beliefs in response to new information and the success and failure of their bets. Below were review some of the promising cognitive mechanisms posited to explain some of the deviations above and which can be evaluated in light of our data.

%2) Cognitive mechanisms 
%Interesting mechanisms have to do with how people organize the hypothesis space and sample from it. 
%- sampling hypothesis
%- change of paradigm when observing "surprising events" (Ortoleva)

%the satisficing principle may also mediate the learning process because computations such as bayes rules are costly. 
